{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figuras/keras-logo-2018-large-1200.png\" width=\"75%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Keras](http://keras.io) es una API de redes neuronales de alto nivel, escrita en Python y capaz de ejecutarse sobre TensorFlow, CNTK o Theano. Fue desarrollado con un enfoque en permitir la experimentación rápida. Poder pasar de la idea al resultado con la menor demora posible es la clave para hacer una buena investigación.\n",
    "\n",
    "Use Keras si necesita una biblioteca de aprendizaje profundo que:\n",
    "\n",
    "- Permite la creación de prototipos fácil y rápida (a través de la facilidad de uso, la modularidad y la extensibilidad).\n",
    "- Admite redes convolucionales y redes recurrentes, así como combinaciones de las dos.\n",
    "- Se ejecuta sin problemas en la CPU y la GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principios rectores\n",
    "\n",
    "- **La facilidad de uso**. Keras es una API diseñada para seres humanos, no máquinas. Pone la experiencia del usuario al frente y al centro. Keras sigue las mejores prácticas para reducir la carga cognitiva: ofrece API consistentes y simples, minimiza el número de acciones de usuario requeridas para casos de uso común y proporciona comentarios claros y procesables ante el error del usuario.\n",
    "- **Modularidad**. Un modelo se entiende como una secuencia o un gráfico de módulos independientes y completamente configurables que se pueden conectar con la menor cantidad de restricciones posible. En particular, las capas neuronales, las funciones de costos, los optimizadores, los esquemas de inicialización, las funciones de activación y los esquemas de regularización son todos módulos independientes que puede combinar para crear nuevos modelos.\n",
    "- **Facilita la extensibilidad**. Los nuevos módulos son simples de agregar (como nuevas clases y funciones), y los módulos existentes brindan amplios ejemplos. Para poder crear fácilmente nuevos módulos permite una total expresividad, lo que hace que Keras sea adecuado para la investigación avanzada.\n",
    "- **Trabaja con Python**. No hay archivos de configuración de modelos por separado en un formato declarativo. Los modelos se describen en el código de Python, que es compacto, más fácil de depurar y permite facilidad de extensión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalación\n",
    "\n",
    "Antes de instalar Keras, instale uno de sus motores bases: TensorFlow, Theano o CNTK. Se recomienda TensorFlow.\n",
    "\n",
    "Instalar Keras usando pip\n",
    "```python\n",
    "pip install keras\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconocimiento de los dígitos MNIST usando Keras\n",
    "\n",
    "### Cargar el conjunto de datos MNIST en Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La biblioteca de aprendizaje profundo Keras proporciona un método conveniente para cargar el conjunto de datos MNIST.\n",
    "\n",
    "El conjunto de datos se descarga automáticamente la primera vez que se llama a esta función y se almacena en su directorio de inicio en `~/.keras/datasets/mnist.pkl.gz` como un archivo de 15 MB.\n",
    "\n",
    "Esto es muy útil para desarrollar y probar modelos de aprendizaje profundo.\n",
    "\n",
    "Para demostrar lo fácil que es cargar el conjunto de datos de MNIST, primero escribiremos un pequeño script para descargar y visualizar las primeras 4 imágenes en el conjunto de datos de capacitación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAD8CAYAAAABraMFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5kdETmLzIyIn/R+KxB3xQTzcVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1834e3b0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Plot ad hoc mnist instances\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "# cargar (descargar si es necesario) el conjunto de datos MNIST \n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# graficar 4 imágenes en escala de grices\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "# mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Base con un Perceptron Multicapa\n",
    "\n",
    "¿Realmente necesitamos un modelo complejo como una red neuronal convolucional para obtener los mejores resultados con MNIST?\n",
    "\n",
    "Puede obtener muy buenos resultados utilizando un modelo de red neuronal muy simple con una sola capa oculta. En esta sección crearemos un modelo de perceptrón multicapa simple que logre una tasa de error de 1.74%. Usaremos esto como línea de base para comparar modelos de redes neuronales convolucionales más complejos.\n",
    "\n",
    "Comencemos importando las clases y funciones que necesitaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siempre es una buena idea inicializar el generador de números aleatorios en una constante para garantizar que los resultados de su secuencia de comandos sean reproducibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fijar la semilla del generador de números aleatorios para reproducibilidad\n",
    "semilla = 7\n",
    "numpy.random.seed(semilla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos cargar el conjunto de datos MNIST utilizando la función auxiliar Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar los data\n",
    "(X_entrenamiento, y_entrenamiento), (X_prueba, y_prueba) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos de entrenamiento está estructurado como una matriz tridimensional de instancia, ancho de imagen y altura de la imagen. Para un modelo de perceptrón multicapa, debemos reducir las imágenes a un vector de píxeles. En este caso, las imágenes de 28 × 28 serán de 784 píxeles.\n",
    "\n",
    "Podemos hacer que esto se transforme fácilmente usando la función `reshape()` de NumPy. También podemos reducir nuestros requisitos de memoria forzando la precisión de los valores de píxel a 32 bits, la precisión predeterminada utilizada por Keras de todos modos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplanar las imágenes de 28*28 a un vector de 784 por cada imagen\n",
    "num_pixeles = X_entrenamiento.shape[1] * X_entrenamiento.shape[2]\n",
    "X_entrenamiento = X_entrenamiento.reshape(X_train.shape[0], num_pixeles).astype('float32')\n",
    "X_prueba = X_prueba.reshape(X_prueba.shape[0], num_pixeles).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores de píxel son escala de grises entre 0 y 255. Casi siempre es una buena idea realizar algún escalamiento valores de entrada cuando se usan modelos de redes neuronales. Debido a que la escala es bien conocida y se comporta bien, podemos normalizar muy rápidamente los valores de píxel en el rango 0 y 1 dividiendo cada valor por el máximo de 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizar las entradas de 0-255 a 0-1\n",
    "X_entrenamiento = X_entrenamiento / 255\n",
    "X_prueba = X_prueba / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, la variable de salida es un número entero de 0 a 9. Este es un problema de clasificación de clase múltiple. Como tal, es una buena práctica usar una codificación \"one-hot\" de los valores de clase, transformando el vector de los enteros de clase en una matriz binaria.\n",
    "\n",
    "Podemos hacer esto fácilmente usando la función auxiliar integrada `np_utils.to_categorical()` en Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codificar salidas como \"one hot\"\n",
    "y_entrenamiento = np_utils.to_categorical(y_entrenamiento)\n",
    "y_prueba = np_utils.to_categorical(y_prueba)\n",
    "num_clases = y_prueba.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora estamos listos para crear nuestro modelo de red neuronal simple. Definiremos nuestro modelo en una función. Esto es útil si desea extender el ejemplo más adelante e intentar obtener una mejor puntuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir modelo base\n",
    "def modelo_base():\n",
    "    # crear modelo\n",
    "    modelo = Sequential()\n",
    "    modelo.add(Dense(num_pixeles, input_dim=num_pixeles, kernel_initializer='normal', activation='relu'))\n",
    "    modelo.add(Dense(num_clases, kernel_initializer='normal', activation='softmax'))\n",
    "    # Compilar el modelo\n",
    "    modelo.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo es una red neuronal simple con una capa oculta con el mismo número de neuronas que entradas (784). Se usa una función de activación ReLU para las neuronas en la capa oculta.\n",
    "\n",
    "Se usa una función de activación de softmax en la capa de salida para convertir las salidas en valores similares a la probabilidad y permitir que una clase de los 10 sea seleccionada como la predicción de salida del modelo. La pérdida logarítmica se usa como la función de pérdida (llamada `categórica_crossentropy` en Keras) y el algoritmo eficiente de descenso de gradiente ADAM se utiliza para aprender los pesos.\n",
    "\n",
    "Ahora podemos ajustar y evaluar el modelo. El modelo se entrena sobre 10 épocas con actualizaciones cada 200 imágenes. Los datos de prueba se utilizan como el conjunto de datos de validación, lo que le permite ver la habilidad del modelo mientras se entrena. Un valor detallado de 2 se usa para reducir la salida a una línea para cada época de entrenamiento.\n",
    "\n",
    "Finalmente, el conjunto de datos de prueba se usa para evaluar el modelo y se imprime una tasa de error de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 6s - loss: 0.2781 - acc: 0.9210 - val_loss: 0.1416 - val_acc: 0.9574\n",
      "Epoch 2/10\n",
      " - 6s - loss: 0.1115 - acc: 0.9679 - val_loss: 0.0919 - val_acc: 0.9710\n",
      "Epoch 3/10\n",
      " - 6s - loss: 0.0718 - acc: 0.9797 - val_loss: 0.0796 - val_acc: 0.9763\n",
      "Epoch 4/10\n",
      " - 7s - loss: 0.0503 - acc: 0.9858 - val_loss: 0.0750 - val_acc: 0.9764\n",
      "Epoch 5/10\n",
      " - 7s - loss: 0.0372 - acc: 0.9895 - val_loss: 0.0680 - val_acc: 0.9788\n",
      "Epoch 6/10\n",
      " - 6s - loss: 0.0269 - acc: 0.9926 - val_loss: 0.0638 - val_acc: 0.9801\n",
      "Epoch 7/10\n",
      " - 6s - loss: 0.0210 - acc: 0.9948 - val_loss: 0.0632 - val_acc: 0.9803\n",
      "Epoch 8/10\n",
      " - 6s - loss: 0.0139 - acc: 0.9972 - val_loss: 0.0628 - val_acc: 0.9804\n",
      "Epoch 9/10\n",
      " - 6s - loss: 0.0106 - acc: 0.9980 - val_loss: 0.0596 - val_acc: 0.9809\n",
      "Epoch 10/10\n",
      " - 6s - loss: 0.0079 - acc: 0.9986 - val_loss: 0.0611 - val_acc: 0.9809\n",
      "Error PMC: 1.91%\n"
     ]
    }
   ],
   "source": [
    "# construir el modelo\n",
    "modelo = modelo_base()\n",
    "# Entrenar el modelo\n",
    "modelo.fit(X_entrenamiento, y_entrenamiento, validation_data=(X_prueba, y_prueba), epochs=10, batch_size=200, verbose=2)\n",
    "# Evaluación final del modelo\n",
    "puntuacion = modelo.evaluate(X_prueba, y_prueba, verbose=0)\n",
    "print(\"Error PMC: %.2f%%\" % (100-puntuacion[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutar el ejemplo puede tomar unos minutos cuando se ejecuta en una CPU. Debería ver el resultado a continuación. Esta red muy simple definida en muy pocas líneas de código logra una tasa de error respetable de 1.91%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Neuronal Convolucional Sencilla para MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que hemos visto cómo cargar el conjunto de datos MNIST y formar un modelo de perceptrón multicapa simple, es hora de desarrollar una red neuronal convolucional más sofisticada o un modelo CNN.\n",
    "\n",
    "Keras proporciona mucha capacidad para crear redes neuronales convolucionales.\n",
    "\n",
    "En esta sección crearemos una CNN simple para MNIST que demuestre cómo utilizar todos los aspectos de una implementación de CNN moderna, incluyendo capas convolucionales, capas de reducción y capas de deserción.\n",
    "\n",
    "El primer paso es importar las clases y funciones necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siempre es una buena idea inicializar el generador de números aleatorios en una constante para garantizar que los resultados de su secuencia de comandos sean reproducibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fijar la semilla del generador de números aleatorios para reproducibilidad\n",
    "semilla = 7\n",
    "numpy.random.seed(semilla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, debemos cargar el conjunto de datos MNIST y remodelarlo para que sea adecuado para usarlos en el entrenamiento de una Red Neuronal Convolucional. En Keras, las capas utilizadas para convoluciones bidimensionales esperan valores de píxeles con las dimensiones [píxeles] [ancho] [altura].\n",
    "\n",
    "En el caso de RGB, los píxeles de la primera dimensión serían 3 para los componentes rojo, verde y azul, y sería como tener 3 entradas de imagen para cada imagen en color. En el caso de MNIST donde los valores de píxel son escala de grises, la dimensión de píxel se establece en 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar los data\n",
    "(X_entrenamiento, y_entrenamiento), (X_prueba, y_prueba) = mnist.load_data()\n",
    "# Remodelar para que sea: [ejemplos][pixeles][ancho][altura]\n",
    "X_entrenamiento = X_entrenamiento.reshape(X_entrenamiento.shape[0], 1, 28, 28).astype('float32')\n",
    "X_prueba = X_prueba.reshape(X_prueba.shape[0], 1, 28, 28).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como antes, es una buena idea normalizar los valores de píxel en el rango 0 y 1 y uno codificar en caliente las variables de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizar las entradas de 0-255 a 0-1\n",
    "X_entrenamiento = X_entrenamiento / 255\n",
    "X_prueba = X_prueba / 255\n",
    "# codificar salidas como \"one hot\"\n",
    "y_entrenamiento = np_utils.to_categorical(y_entrenamiento)\n",
    "y_prueba = np_utils.to_categorical(y_prueba)\n",
    "num_clases = y_prueba.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación definimos nuestro modelo de red neuronal.\n",
    "\n",
    "Las redes neuronales convolucionales son más complejas que los perceptrones multicapa estándar, por lo que comenzaremos por usar una estructura simple para empezar que utilice todos los elementos para obtener resultados de vanguardia. A continuación se resume la arquitectura de la red.\n",
    "\n",
    "1. La primera capa oculta es una capa convolucional llamada Convolution2D. La capa tiene 32 mapas de características, que con el tamaño de 5 × 5 y una función de activación del rectificador. Esta es la capa de entrada, esperando imágenes con el esquema de estructura arriba [píxeles] [ancho] [alto].\n",
    "2. A continuación, definimos una capa de agrupación que toma el máximo llamado MaxPooling2D. Está configurado con un tamaño de grupo de 2 × 2.\n",
    "3. La siguiente capa es una capa de regularización que utiliza el apagado aleatorio. Está configurado para excluir aleatoriamente el 20% de las neuronas en la capa con el fin de reducir el sobreajuste.\n",
    "4. La siguiente es una capa que convierte los datos de la matriz 2D a un vector llamado Flatten. Permite que la salida sea procesada por capas estándar totalmente conectadas.\n",
    "5. A continuación, una capa completamente conectada con 128 neuronas y la función de activación del rectificador.\n",
    "6. Finalmente, la capa de salida tiene 10 neuronas para las 10 clases y una función de activación de softmax para emitir predicciones de probabilidad para cada clase.\n",
    "\n",
    "Como antes, el modelo se entrena usando pérdida logarítmica y el algoritmo de descenso de gradiente ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo_base():\n",
    "    # crear modelo\n",
    "    modelo = Sequential()\n",
    "    modelo.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "    modelo.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    modelo.add(Dropout(0.2))\n",
    "    modelo.add(Flatten())\n",
    "    modelo.add(Dense(128, activation='relu'))\n",
    "    modelo.add(Dense(num_clases, activation='softmax'))\n",
    "    # Compilar modelo\n",
    "    modelo.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos el modelo de la misma manera que antes con el perceptrón multicapa. La CNN se etrena sobre 10 épocas con un tamaño de lote de 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 127s - loss: 0.2320 - acc: 0.9342 - val_loss: 0.0812 - val_acc: 0.9748\n",
      "Epoch 2/10\n",
      " - 127s - loss: 0.0737 - acc: 0.9782 - val_loss: 0.0469 - val_acc: 0.9839\n",
      "Epoch 3/10\n",
      " - 128s - loss: 0.0532 - acc: 0.9839 - val_loss: 0.0432 - val_acc: 0.9863\n",
      "Epoch 4/10\n",
      " - 129s - loss: 0.0401 - acc: 0.9880 - val_loss: 0.0400 - val_acc: 0.9868\n",
      "Epoch 5/10\n",
      " - 130s - loss: 0.0334 - acc: 0.9894 - val_loss: 0.0345 - val_acc: 0.9882\n",
      "Epoch 6/10\n",
      " - 131s - loss: 0.0273 - acc: 0.9917 - val_loss: 0.0307 - val_acc: 0.9898\n",
      "Epoch 7/10\n",
      " - 128s - loss: 0.0230 - acc: 0.9929 - val_loss: 0.0342 - val_acc: 0.9883\n",
      "Epoch 8/10\n",
      " - 135s - loss: 0.0200 - acc: 0.9937 - val_loss: 0.0313 - val_acc: 0.9897\n",
      "Epoch 9/10\n",
      " - 136s - loss: 0.0167 - acc: 0.9946 - val_loss: 0.0310 - val_acc: 0.9899\n",
      "Epoch 10/10\n",
      " - 135s - loss: 0.0138 - acc: 0.9959 - val_loss: 0.0334 - val_acc: 0.9893\n",
      "Error RNC: 1.07%\n"
     ]
    }
   ],
   "source": [
    "# construir el modelo\n",
    "modelo = modelo_base()\n",
    "# Entrenar el modelo\n",
    "modelo.fit(X_entrenamiento, y_entrenamiento, validation_data=(X_prueba, y_prueba), epochs=10, batch_size=200, verbose=2)\n",
    "# Evaluación final del modelo\n",
    "puntuacion = modelo.evaluate(X_prueba, y_prueba, verbose=0)\n",
    "print(\"Error RNC: %.2f%%\" % (100-puntuacion[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutando el ejemplo, la precisión en la prueba de entrenamiento y validación se imprime en cada época y al final de la tasa de error de clasificación se imprime.\n",
    "\n",
    "Las épocas pueden tardar unos 45 segundos en ejecutarse en la GPU (por ejemplo, en AWS). Puede ver que la red alcanza una tasa de error de 1.07, que es mejor que nuestro modelo de perceptrón multicapa simple anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Neuronal Convolucional Compleja para MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que hemos visto cómo crear una CNN simple, echemos un vistazo a un modelo capaz de obtener resultados de última generación.\n",
    "\n",
    "Importamos clases y funciones, luego cargamos y preparamos los datos de la misma manera que en el ejemplo anterior de CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red Neuronal compleja para el conjunto de datos de MNIST\n",
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "# fijar la semilla del generador de números aleatorios para reproducibilidad\n",
    "semilla = 7\n",
    "numpy.random.seed(semilla)\n",
    "# cargar los data\n",
    "(X_entrenamiento, y_entrenamiento), (X_prueba, y_prueba) = mnist.load_data()\n",
    "# Remodelar para que sea: [ejemplos][pixeles][ancho][altura]\n",
    "X_entrenamiento = X_entrenamiento.reshape(X_entrenamiento.shape[0], 1, 28, 28).astype('float32')\n",
    "X_prueba = X_prueba.reshape(X_prueba.shape[0], 1, 28, 28).astype('float32')\n",
    "# normalizar las entradas de 0-255 a 0-1\n",
    "X_entrenamiento = X_entrenamiento / 255\n",
    "X_prueba = X_prueba / 255\n",
    "# codificar salidas como \"one hot\"\n",
    "y_entrenamiento = np_utils.to_categorical(y_entrenamiento)\n",
    "y_prueba = np_utils.to_categorical(y_prueba)\n",
    "num_clases = y_prueba.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta vez, definimos una gran arquitectura CNN con capas convolucionales adicionales, agrupaciones máximas y capas completamente conectadas. La topología de red se puede resumir de la siguiente manera.\n",
    "\n",
    "1. Capa convolucional con 30 mapas de características de tamaño 5 × 5.\n",
    "2. Combinando la capa tomando el máximo de 2 * 2 parches.\n",
    "3. Capa convolucional con 15 mapas de características de tamaño 3 × 3.\n",
    "4. Combinando la capa tomando el máximo de 2 * 2 parches.\n",
    "5. Capa de deserción con una probabilidad del 20%.\n",
    "6. Aplanar la capa.\n",
    "7. Capa completamente conectada con 128 neuronas y activación del rectificador.\n",
    "8. Capa completamente conectada con 50 neuronas y activación del rectificador.\n",
    "9. Capa de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the larger model\n",
    "def modelo_complejo():\n",
    "    # crear modelo\n",
    "    modelo = Sequential()\n",
    "    modelo.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "    modelo.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    modelo.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "    modelo.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    modelo.add(Dropout(0.2))\n",
    "    modelo.add(Flatten())\n",
    "    modelo.add(Dense(128, activation='relu'))\n",
    "    modelo.add(Dense(50, activation='relu'))\n",
    "    modelo.add(Dense(num_clases, activation='softmax'))\n",
    "    # Compilar modelo\n",
    "    modelo.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos el modelo de la misma manera que antes con el perceptrón multicapa. La CNN se etrena sobre 10 épocas con un tamaño de lote de 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 127s - loss: 0.3901 - acc: 0.8757 - val_loss: 0.0804 - val_acc: 0.9755\n",
      "Epoch 2/10\n",
      " - 179s - loss: 0.0979 - acc: 0.9692 - val_loss: 0.0506 - val_acc: 0.9854\n",
      "Epoch 3/10\n",
      " - 185s - loss: 0.0721 - acc: 0.9778 - val_loss: 0.0365 - val_acc: 0.9889\n",
      "Epoch 4/10\n",
      " - 191s - loss: 0.0593 - acc: 0.9818 - val_loss: 0.0338 - val_acc: 0.9890\n",
      "Epoch 5/10\n",
      " - 173s - loss: 0.0476 - acc: 0.9851 - val_loss: 0.0308 - val_acc: 0.9900\n",
      "Epoch 6/10\n",
      " - 175s - loss: 0.0437 - acc: 0.9865 - val_loss: 0.0289 - val_acc: 0.9899\n",
      "Epoch 7/10\n",
      " - 176s - loss: 0.0373 - acc: 0.9880 - val_loss: 0.0304 - val_acc: 0.9904\n",
      "Epoch 8/10\n",
      " - 175s - loss: 0.0337 - acc: 0.9892 - val_loss: 0.0254 - val_acc: 0.9907\n",
      "Epoch 9/10\n",
      " - 175s - loss: 0.0314 - acc: 0.9905 - val_loss: 0.0251 - val_acc: 0.9916\n",
      "Epoch 10/10\n",
      " - 171s - loss: 0.0289 - acc: 0.9908 - val_loss: 0.0275 - val_acc: 0.9911\n",
      "Error RNC compleja: 0.89%\n"
     ]
    }
   ],
   "source": [
    "# construir el modelo\n",
    "modelo = modelo_complejo()\n",
    "# Entrenar el modelo\n",
    "modelo.fit(X_entrenamiento, y_entrenamiento, validation_data=(X_prueba, y_prueba), epochs=10, batch_size=200, verbose=2)\n",
    "# Evaluación final del modelo\n",
    "puntuacion = modelo.evaluate(X_prueba, y_prueba, verbose=0)\n",
    "print(\"Error RNC compleja: %.2f%%\" % (100-puntuacion[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ejecutar el ejemplo, se imprime la precisión en los conjuntos de datos de capacitación y validación de cada época y una tasa de error de clasificación final.\n",
    "\n",
    "El modelo tarda aproximadamente 100 segundos en ejecutarse por época. Este modelo un poco más grande logra la tasa de error de clasificación respetable de 0,89%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
