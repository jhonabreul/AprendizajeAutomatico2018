{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figuras/tensorflow.png\" width=\"25%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué es TensorFlow?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow se describe como \"una interfaz para expresar algoritmos de aprendizaje automático y una implementación para ejecutar dichos algoritmos\". Su principal ventaja sobre otros frameworks es lo fácil que es ejecutar el código en una amplia gama de dispositivos. Esto está relacionado con la motivación inicial para su desarrollo, antes de que fuera de código abierto. Inicialmente, Google desarrolló TensorFlow para cerrar la brecha entre la investigación y la producción, y aspiraba a un ideal en el que no se debían realizar modificaciones al código para pasar de la investigación a la producción. Para lograr esto, TensorFlow implementa un grafo computacional de tu código, estás definiendo y solo definiendo ese grafo: el flujo de tensores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué es un Tensor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que un vector puede considerarse como una matriz, o una lista, de escalares (números ordinarios como 1, 2 y PI), y las matrices pueden considerarse matrices de vectores, un tensor puede considerarse como un matriz de matrices. Entonces un tensor es realmente solo una matriz n-dimensional. Resulta, como veremos en los ejemplos de codificación, que esta arquitectura tiene mucho sentido cuando se trabaja con el aprendizaje automático.\n",
    "\n",
    "En TensorFlow, los tensores se describen mediante una unidad de dimensionalidad conocida como orden. El orden de Tensor no es lo mismo que el orden de la matriz. El orden del tensor es el número de dimensiones del tensor.\n",
    "\n",
    "Un tensor de orden dos es lo que típicamente pensamos como una matriz, un tensor de orden uno es un vector. Para un tensor de orden dos, puede acceder a cualquier elemento con la sintaxis `t[i, j]`. Para un tensor de orden tres, los elementos de direccionan con `t[i, j, k]`.\n",
    "\n",
    "<img src=\"figuras/tensor_rank.png\" width=\"75%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafo Computacional en TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow nos permite implementar algoritmos de aprendizaje automático mediante la creación y el cálculo de operaciones que interactúan entre sí. Estas interacciones forman lo que llamamos un \"grafo computacional\", con el cual podemos intuitivamente representar arquitecturas funcionales complicadas.\n",
    "\n",
    "Un grafo se refiere a un conjunto de entidades interconectadas, comúnmente llamadas nodos o vértices. Estos nodos están conectados entre sí a través de las aristas. En un grafo de flujo de datos, las aristas permiten que los datos \"fluyan\" de un nodo a otro de una manera dirigida.\n",
    "\n",
    "En TensorFlow, cada uno de los nodos del grafo representa una operación, posiblemente aplicada a alguna entrada, y puede generar un resultado que se transmite a otros nodos. Por analogía, podemos pensar en el grafo computacional como una línea de ensamblaje donde cada máquina (nodo) obtiene o crea su materia prima (entrada), la procesa y luego pasa la salida a otras máquinas de manera ordenada.\n",
    "\n",
    "Considere la siguiente expresión:\n",
    "\n",
    "$$f = \\frac{1}{1+exp^{-(w_0x_0+w_1x_1+w_2)}}$$\n",
    "\n",
    "Podemos dividir esta función en los siguientes componentes:\n",
    "\n",
    "$$operacion_1 = w_0 \\times x_0$$\n",
    "\n",
    "$$operacion_2 = w_1 \\times x_1$$\n",
    "\n",
    "$$operacion_3 = operacion_1 + operacion_2$$\n",
    "\n",
    "$$operacion_4 = operacion_3 + w_2$$\n",
    "\n",
    "$$operacion_5 = -1 \\times operacion_4$$\n",
    "\n",
    "$$operacion_6 = exp^{operacion_5}$$\n",
    "\n",
    "$$operacion_7 = 1 + operacion_6$$\n",
    "\n",
    "$$f = \\frac{1}{operacion_7}$$\n",
    "\n",
    "Ahora podemos representar estas operaciones en un grafo:\n",
    "\n",
    "<img src=\"figuras/GrafoSigmoide.png\" width=\"75%\">\n",
    "\n",
    "Esto puede parecer un ejemplo tonto, pero observe una idea poderosa al expresar la ecuación de esta manera: dos de los cálculos ($operacion_1 = w_0 \\times x_0$ y $operacion_2 = w_1 \\times x_1$) se pueden realizar en paralelo. Al dividir estos cálculos entre CPU o GPU, esto puede darnos ganancias significativas en tiempos de computación. Estas ganancias son imprescindibles para aplicaciones de datos masivos (big data) y aprendizaje profundo, especialmente para arquitecturas de redes neuronales complicadas como las Redes Neuronales Convolucionales (CNN) y las Redes Neuronales Recurrentes (RNN). La idea detrás de TensorFlow es la capacidad de crear estos gráficos computacionales en código y permitir importantes mejoras de rendimiento a través de operaciones paralelas y otras ganancias de eficiencia.\n",
    "\n",
    "Los flujos de datos tiene varias ventajas que TensorFlow aprovecha al ejecutar sus programas:\n",
    "- **Paralelismo**. Al usar aristas explícitas para representar dependencias entre operaciones, es fácil para el sistema identificar operaciones que pueden ejecutarse en paralelo.\n",
    "- **Ejecución distribuida**. Al usar aristas explícitas para representar los valores que fluyen entre las operaciones, es posible que TensorFlow particione su programa en varios dispositivos (CPU, GPU y TPU) conectados a diferentes máquinas. TensorFlow inserta la comunicación y coordinación necesarias entre los dispositivos.\n",
    "- **Compilación**. El compilador XLA de TensorFlow puede usar la información en su grafo de flujo de datos para generar código más rápido, por ejemplo, fusionando operaciones adyacentes.\n",
    "- **Portabilidad**. El grafo de flujo de datos es una representación independiente del lenguaje del código en su modelo. Puede construir un gráfico de flujo de datos en Python, almacenarlo en un `SavedModel` y restaurarlo en un programa C ++ para una inferencia de baja latencia.\n",
    "\n",
    "A continuación podemos ver un grafo similar en TensorFlow, que muestra el grafo computacional de una red neuronal de tres capas:\n",
    "\n",
    "<img src=\"figuras/TensorFlow-data-flow-graph.gif\" width=\"25%\">\n",
    "\n",
    "La animación del flujos de datos entre los diferentes nodos en el grafo son tensores que son matrices de datos multidimensionales. Por ejemplo, el tensor de datos de entrada puede ser de 5000 x 64 x 1, que representa una capa de entrada de 64 nodos con 5000 muestras de entrenamiento. Después de la capa de entrada, hay una capa oculta con unidades lineales rectificadas (ReLU) como función de activación. Hay una capa de salida final (llamada \"capa de logit\" en el grafo anterior) que usa la entropía cruzada como una función de costo / pérdida. En cada punto vemos los tensores relevantes que fluyen al bloque \"Gradientes\" que finalmente fluyen al optimizador de Descenso Gradual Estocástico que realiza la propagación hacia atrás y el descenso del gradiente.\n",
    "\n",
    "Aquí podemos ver cómo los grafos computacionales se pueden usar para representar los cálculos en redes neuronales, y esto, por supuesto, es en lo que sobresale TensorFlow. Veamos cómo realizar algunas operaciones matemáticas básicas en TensorFlow para tener una idea de cómo funciona todo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero hagamos que TensorFlow realice el cálculo de la siguiente función: $f = \\frac{1}{1+exp^{-(w_0x_0+w_1x_1+w_2)}}$. Primero, debemos introducir a las variables y constantes de TensorFlow. Vamos a declararlas y luego se explicará la sintaxis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wladimir/anaconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importar tensorflow\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear las constantes\n",
    "uno = tf.constant(1.0, name=\"uno\")\n",
    "menos_uno = tf.constant(-1.0, name=\"menos_uno\")\n",
    "\n",
    "# crear las variables\n",
    "w0 = tf.Variable(2.0, name='w0')\n",
    "x0 = tf.Variable(-1.0, name='x0')\n",
    "w1 = tf.Variable(-3.0, name='w1')\n",
    "x1 = tf.Variable(-2.0, name='x1')\n",
    "w2 = tf.Variable(-3.0, name='w2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar anteriormente, las constantes de TensorFlow se pueden declarar utilizando la función `tf.constant` y las variables con la función `tf.Variable`. El primer elemento en ambos es el valor que se le asignará a la constante/variable cuando se inicializa. La segunda es una cadena de nombre opcional que se puede utilizar para etiquetar la constante/variable; esto es útil para cuando se quiere hacer visualizaciones. TensorFlow deducirá el tipo de la constante/variable a partir del valor inicial, pero también se puede establecer explícitamente utilizando el argumento opcional `dtype`. TensorFlow tiene muchos de sus propios tipos, como `tf.float32`, `tf.int32`, etc.\n",
    "\n",
    "Es importante tener en cuenta que, como el código de Python se ejecuta a través de estos comandos, las variables no se han declarado realmente como lo habrían sido si hubiera sido una declaración de Python estándar (es decir, b = 2.0). En cambio, todas las constantes, variables, operaciones y el grafo computacional solo se crean cuando se ejecutan los comandos de inicialización.\n",
    "\n",
    "A continuación, creamos las operaciones de TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora se crean las operaciones\n",
    "operacion1 = tf.multiply(w0, x0, name='operacion1')\n",
    "operacion2 = tf.multiply(w1, x1, name='operacion2')\n",
    "operacion3 = tf.add(operacion1, operacion2, name='operacion3')\n",
    "operacion4 = tf.add(operacion3, w2, name='operacion4')\n",
    "operacion5 = tf.multiply(operacion4, menos_uno, name='operacion5')\n",
    "operacion6 = tf.exp(operacion5, name='operacion6')\n",
    "operacion7 = tf.add(operacion6, uno, name='operacion7')\n",
    "f = tf.divide(uno, operacion7, name='f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow tiene una gran cantidad de operaciones disponibles para realizar todo tipo de interacciones entre variables, algunas de las cuales veremos más adelante. Las operaciones anteriores son bastante obvias, y crean las instancias de las operaciones.\n",
    "\n",
    "El siguiente paso es configurar un objeto para inicializar las variables y la estructura del grafo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialización de las variable\n",
    "inicializar = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, entonces ahora estamos listos para realizar la computación. Para ejecutar las operaciones entre las variables, necesitamos iniciar una sesión de TensorFlow - `tf.Session`. La sesión de TensorFlow es un objeto donde se ejecutan todas las operaciones. Usando la sintaxis `with` de Python, podemos ejecutar el gráfico con el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable f es 0.7310585975646973\n"
     ]
    }
   ],
   "source": [
    "# arrancar la sesión\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(\"sigmoide\", sess.graph)\n",
    "    # inicializar las variables\n",
    "    sess.run(inicializar)\n",
    "    # computar la salida del grafo\n",
    "    f_salida = sess.run(f)\n",
    "    print(\"Variable f es {}\".format(f_salida))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer comando dentro del bloque `with` es la inicialización, que se ejecuta con el comando `run`. Luego queremos averiguar cuál debe ser el valor de la variable $f$. Todo lo que tenemos que hacer es ejecutar la operación que calcula $f$, por ejemplo, `f = tf.divide(uno, operacion7, name='f')`. Tenga en cuenta que $f$ es una operación, no una variable y, por lo tanto, se puede ejecutar. Hacemos eso con el comando `sess.run(f)` y asignamos el resultado a `f_salida`, cuyo valor luego imprimimos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe algo interesante: definimos las operaciones $operacion1$, $operacion2$, $operacion3$, $operacion4$, $operacion5$, $operacion6$ y $operacion7$ que deben calcularse antes de poder determinar el valor de $f$. Sin embargo, no tenemos que ejecutar explícitamente esas operaciones, ya que TensorFlow sabe de qué otras operaciones y variables depende la operación $f$, y por lo tanto ejecuta las operaciones necesarias por sí mismo. Hace esto a través de su grafo de flujo de datos que muestra todas las dependencias requeridas. Usando la funcionalidad TensorBoard, podemos ver el grafo que TensorFlow creó para este pequeño programa:\n",
    "\n",
    "<img src=\"figuras/Grafo_f.png\" width=\"75%\">\n",
    "\n",
    "¿Y si tuviéramos un arreglo de valores $w_2$ para calcular el valor de una vez más?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El marcador de posición \"Placeholder\" de TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digamos también que no sabíamos cuál sería el valor del arreglo $b$ durante la fase de declaración del problema TensorFlow (es decir, antes de la etapa `tf.Sesión() as sess`). En este caso, TensorFlow nos exige que declaremos la estructura básica de los datos mediante el uso de la declaración de variable `tf.placeholder`. Vamos a usarlo para $b$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# crear placeholder\n",
    "w2 = tf.placeholder(tf.float32, [None, 1], name='w2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que no proporcionamos una inicialización en esta declaración, debemos decirle a TensorFlow qué tipo de datos va a ser cada elemento dentro del tensor. En este caso, queremos usar `tf.float32`. El segundo argumento es la forma de los datos que serán \"inyectados\" en esta variable. En este caso, queremos utilizar una matriz de tamaño (? X 1), porque estamos siendo cautelosos sobre la cantidad de datos que estamos suministrando a esta variable (de ahí el \"?\"), El marcador de posición está dispuesto a aceptar un argumento `None` en la declaración de tamaño. Ahora podemos inyectar tantos datos unidimensionales como queramos en la variable `w2`.\n",
    "\n",
    "El único cambio que debemos hacer en nuestro programa está en el comando `sess.run (f, ...)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable f es [[0.26894143]\n",
      " [0.5       ]\n",
      " [0.7310586 ]\n",
      " [0.880797  ]\n",
      " [0.95257413]\n",
      " [0.98201376]\n",
      " [0.9933072 ]\n",
      " [0.9975274 ]\n",
      " [0.999089  ]\n",
      " [0.99966466]]\n"
     ]
    }
   ],
   "source": [
    "# crear las constantes\n",
    "uno = tf.constant(1.0, name=\"uno\")\n",
    "menos_uno = tf.constant(-1.0, name=\"menos_uno\")\n",
    "\n",
    "# crear las variables\n",
    "w0 = tf.Variable(2.0, name='w0')\n",
    "x0 = tf.Variable(-1.0, name='x0')\n",
    "w1 = tf.Variable(-3.0, name='w1')\n",
    "x1 = tf.Variable(-2.0, name='x1')\n",
    "\n",
    "# ahora se crean las operaciones\n",
    "operacion1 = tf.multiply(w0, x0, name='operacion1')\n",
    "operacion2 = tf.multiply(w1, x1, name='operacion2')\n",
    "operacion3 = tf.add(operacion1, operacion2, name='operacion3')\n",
    "operacion4 = tf.add(operacion3, w2, name='operacion4')\n",
    "operacion5 = tf.multiply(operacion4, menos_uno, name='operacion5')\n",
    "operacion6 = tf.exp(operacion5, name='operacion6')\n",
    "operacion7 = tf.add(operacion6, uno, name='operacion7')\n",
    "f = tf.divide(uno, operacion7, name='f')\n",
    "\n",
    "# Inicialización de las variable\n",
    "inicializar = tf.global_variables_initializer()\n",
    "\n",
    "# arrancar la sesión\n",
    "with tf.Session() as sess:\n",
    "    archivo=\"./summary_log/ejecucion_\"+datetime.datetime.now().strftime(\"%Y-%m-%d--%H-%M-%s\")\n",
    "    writer = tf.summary.FileWriter(archivo, sess.graph)\n",
    "    # inicializar las variables\n",
    "    sess.run(inicializar)\n",
    "    # computar la salida del grafo\n",
    "    f_salida = sess.run(f, feed_dict={w2: np.arange(-5, 5)[:, np.newaxis]})\n",
    "    print(\"Variable f es {}\".format(f_salida))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de una Red Neuronal con TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veremos un ejemplo de la creación de una red neuronal simple de tres capas en TensorFlow. En este ejemplo, usaremos el conjunto de datos MNIST (y su cargador asociado) que proporciona el paquete TensorFlow. Este conjunto de datos MNIST es un conjunto de imágenes en escala de grises de 28 × 28 píxeles que representan dígitos escritos a mano. Tiene 55,000 filas de entrenamiento, 10,000 filas de prueba y 5,000 filas de validación.\n",
    "\n",
    "Cargaremos los datos ejecutando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tamaños de los onjuntos de entrenamiento, validación y prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de:\n",
      "- Conjunto de entrenamiento:\t55000\n",
      "- Conjunto de prueba:\t\t10000\n",
      "- Conjunto de validación:\t5000\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamaño de:\")\n",
    "print(\"- Conjunto de entrenamiento:\\t{}\".format(len(mnist.train.labels)))\n",
    "print(\"- Conjunto de prueba:\\t\\t{}\".format(len(mnist.test.labels)))\n",
    "print(\"- Conjunto de validación:\\t{}\".format(len(mnist.validation.labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificación \"One-Hot\"\n",
    "\n",
    "\n",
    "El argumento `one_hot=True` especifica que en lugar de que las etiquetas asociadas a cada imagen sean el dígito en sí, es decir \"4\", es un vector con un nodo \"caliente\" y todos los otros nodos serán cero, es decir, [0, 0, 0, 0 , 1, 0, 0, 0, 0, 0]. Esto nos permite alimentarlo fácilmente a la capa de salida de nuestra red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.labels[0:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para convertir la codificacioón de los dígitos de \"One-Hot\" a un sólo número, se busca el indice del elemento mayor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digitos = np.array([label.argmax() for label in mnist.test.labels])\n",
    "digitos[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializar variables y \"placeholders\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, podemos configurar las variables de marcador de posición para los datos de entrenamiento (y algunos hiperparámetros de entrenamiento):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hiperparámetros de la red neuronal\n",
    "tasa_aprendizaje = 0.5\n",
    "epocas = 30\n",
    "tamaño_lote = 100\n",
    "\n",
    "\n",
    "# declarar los placeholders para los datos de entrenamiento\n",
    "# entrada x - para 28 x 28 pixels = 784\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "# declarar el placeholder de los datos de salida - 10 dígitos\n",
    "y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que la capa de entrada $x$ es 784 nodos correspondientes a los 28 x 28 (= 784) píxeles, y la capa de salida $y$ es de 10 nodos correspondientes a los 10 dígitos posibles. De nuevo, el tamaño de $x$ es (None X 784), donde el None significa que se ingresará una cantidad de muestras aún no especificada.\n",
    "\n",
    "Ahora necesitamos configurar las variables de pesos y sesgo para la red neuronal de tres capas. Siempre hay un número $L-1$ de tensores de pesos/sesgo, donde $L$ es el número de capas. Entonces, en este caso, necesitamos configurar dos tensores para cada uno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# declarar los pesos conectando la capa de entrada con la capa oculta\n",
    "W1 = tf.Variable(tf.random_normal([784, 300], stddev=0.03), name='W1')\n",
    "b1 = tf.Variable(tf.random_normal([300]), name='b1')\n",
    "# y los pesos conectando la capa oculta con la capa de salidad\n",
    "W2 = tf.Variable(tf.random_normal([300, 10], stddev=0.03), name='W2')\n",
    "b2 = tf.Variable(tf.random_normal([10]), name='b2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, tenemos que configurar las entradas netas a los nodos y las funciones de activación de los nodos de capa oculta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calcular la activación de la capa oculta\n",
    "oculta_entrada = tf.add(tf.matmul(x, W1), b1)\n",
    "oculta_activacion = tf.nn.relu(oculta_entrada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función de activación a utilizar en la capa oculta es ReLU (Rectified Linear Unit):\n",
    "\n",
    "<img src=\"figuras/relu.png\" width=\"50%\">\n",
    "\n",
    "TensorFlow tiene la función de activación ReLU ya configurada, `tf.nn.relu`.\n",
    "\n",
    "Ahora, configuremos la capa de salida, `y_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calcular la activación de la capa de salida - usando la función de activación softmax\n",
    "activacion_salida = tf.nn.softmax(tf.add(tf.matmul(oculta_activacion, W2), b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En matemáticas, la función softmax, o función exponencial normalizada, es una generalización de la función logística. Se emplea para \"comprimir\" un vector K-dimensional, $z$, de valores reales arbitrarios en un vector K-dimensional, $\\sigma(z)$, de valores reales en el rango [0, 1]. La función está dada por:\n",
    "\n",
    "$$\\sigma(z)_j=\\frac{e^{z_j}}{\\sum_{k=1}^{K}e^{z_k}}\\ \\ para\\ j=1,\\dots,K.$$\n",
    "\n",
    "Podemos usar la función softmax de TensorFlow `tf.nn.softmax`.\n",
    "\n",
    "También debemos incluir una función de costo o pérdida para poder realizar la propagación hacia atrás. Aquí usaremos la función de costo de entropía cruzada, representada por:\n",
    "\n",
    "$$J(\\boldsymbol{w})=-\\frac{1}{m}\\sum_{i=1}^{m}\\sum_{j=1}^{n}y^{[i]}log(a^{[i]}_j)+(1-y^{[i]}_j)log(1-a^{[i]}_j)$$\n",
    "\n",
    "Podemos implementar esta función de costo de entropía cruzada en TensorFlow con el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'costo:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activacion_salida_cortada = tf.clip_by_value(activacion_salida, 1e-10, 0.9999999)\n",
    "costo = -tf.reduce_mean(tf.reduce_sum(y * tf.log(activacion_salida_cortada)\n",
    "                         + (1 - y) * tf.log(1 - activacion_salida_cortada), axis=1))\n",
    "tf.summary.scalar('costo', costo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera línea es una operación que convierte la salida `activacion_salida` en una versión recortada, limitada entre 1e-10 y 0.999999. Esto es para asegurarnos de que nunca tengamos el caso durante el entrenamiento de $log(0)$ si esto ocurre, esto devolvería NaN y detendría el proceso de entrenamiento. La segunda línea es el cálculo de entropía cruzada.\n",
    "\n",
    "Para realizar este cálculo, primero usamos la función `tf.reduce_sum` de TensorFlow, esta función básicamente toma la suma de un eje dado del tensor que se suministra. En este caso, el tensor que se suministra es el cálculo de entropía cruzada elemento por elemento para un solo nodo y una muestra de entrenamiento, es decir: $y^{[i]}log(a^{[i]}_j)+(1-y^{[i]}_j)log(1-a^{[i]}_j)$. Recuerde que `activacion_salida` y `activacion_salida_cortada` en el cálculo anterior son tensores `(m x 10)`, por lo tanto, necesitamos realizar la primera suma sobre el segundo eje. Esto se especifica utilizando el argumento `axis=1`.\n",
    "\n",
    "Después de esta operación, tenemos un tensor `(m x 1)`. Para tomar la media de este tensor y completar nuestro cálculo del costo de entropía cruzada (es decir, ejecutar esta parte $-\\frac{1}{m}\\sum_{i=1}^{m}$), utilizamos la función `tf.reduce_mean` de TensorFlow. Esta función simplemente toma la media del tensor que le proporcione. Entonces ahora tenemos una función de costo que podemos usar en el proceso de entrenamineto.\n",
    "\n",
    "Ahora vamos a configurar el optimizador en TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agregar un optimizador\n",
    "optimizador = tf.train.GradientDescentOptimizer(learning_rate=tasa_aprendizaje).minimize(costo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos usando el optimizador de descenso de gradiente proporcionado por TensorFlow. Lo inicializamos con una tasa de aprendizaje, luego especificamos lo que queremos que haga, es decir, minimizar la operación de costo de entropía cruzada que creamos. Esta función luego realizará el descenso de gradiente y la propagación hacia atrás.\n",
    "\n",
    "Finalmente configuremos la operación de inicialización variable y una operación para medir la precisión de nuestras predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inicializar las variables\n",
    "inicializar = tf.global_variables_initializer()\n",
    "\n",
    "# definir la operación de exactitud\n",
    "prediccion_corecta = tf.equal(tf.argmax(y, 1), tf.argmax(activacion_salida, 1))\n",
    "exactitud = tf.reduce_mean(tf.cast(prediccion_corecta, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La operación `predicción_correcta` hace uso de la función `tf.equal` TensorFlow que devuelve True o False dependiendo de si los argumentos proporcionados son iguales. La función `tf.argmax` devuelve el índice del valor máximo en un vector/tensor. Por lo tanto, la operación de `predicción_correcta` devuelve un tensor de tamaño `(m x 1)` de valores True y False que indica si la red neuronal ha predicho correctamente el dígito. Luego queremos calcular la precisión media de este tensor: primero tenemos que convertir el tipo de la operación de `predicción_correcta` de un `Boolean` a un `float` de TensorFlow para realizar la operación `reduce_mean`. Una vez que hayamos hecho eso, ahora tenemos una operación de precisión lista para evaluar el rendimiento de la red neuronal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurar el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos todo lo que necesitamos para configurar el proceso de entrenamiento de nuestra red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'exactitud:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a summary to store the accuracy\n",
    "tf.summary.scalar('exactitud', exactitud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1 costo = 329.1319\n",
      "[0.26382506, 0.9548]\n",
      "[0.25579408, 0.95503634]\n",
      "Epoca: 2 costo = 125.8674\n",
      "[0.17853291, 0.972]\n",
      "[0.1510172, 0.97441816]\n",
      "Epoca: 3 costo = 93.3478\n",
      "[0.16695322, 0.973]\n",
      "[0.12142181, 0.97996366]\n",
      "Epoca: 4 costo = 73.4773\n",
      "[0.15059155, 0.9774]\n",
      "[0.09756623, 0.9827818]\n",
      "Epoca: 5 costo = 59.0319\n",
      "[0.15043469, 0.975]\n",
      "[0.077541605, 0.9876]\n",
      "Epoca: 6 costo = 49.8572\n",
      "[0.1554486, 0.9768]\n",
      "[0.07666577, 0.98752725]\n",
      "Epoca: 7 costo = 41.7925\n",
      "[0.15238985, 0.9748]\n",
      "[0.05496138, 0.9908182]\n",
      "Epoca: 8 costo = 35.5686\n",
      "[0.1429199, 0.9766]\n",
      "[0.04802882, 0.99203634]\n",
      "Epoca: 9 costo = 29.5063\n",
      "[0.13708124, 0.9782]\n",
      "[0.03748573, 0.9940364]\n",
      "Epoca: 10 costo = 25.2513\n",
      "[0.14925934, 0.9772]\n",
      "[0.03324899, 0.99527276]\n",
      "Epoca: 11 costo = 19.1316\n",
      "[0.14687075, 0.9762]\n",
      "[0.030760175, 0.9954]\n",
      "Epoca: 12 costo = 15.2280\n",
      "[0.15102515, 0.9788]\n",
      "[0.023488313, 0.9965636]\n",
      "Epoca: 13 costo = 15.2654\n",
      "[0.14260186, 0.9786]\n",
      "[0.024203219, 0.99645454]\n",
      "Epoca: 14 costo = 10.4007\n",
      "[0.13999547, 0.979]\n",
      "[0.015843838, 0.99807274]\n",
      "Epoca: 15 costo = 8.4025\n",
      "[0.15320925, 0.9794]\n",
      "[0.013001257, 0.9984546]\n",
      "Epoca: 16 costo = 5.1400\n",
      "[0.14573814, 0.979]\n",
      "[0.0065821824, 0.99963635]\n",
      "Epoca: 17 costo = 4.2375\n",
      "[0.1480452, 0.979]\n",
      "[0.0059139156, 0.9996182]\n",
      "Epoca: 18 costo = 3.0044\n",
      "[0.14583741, 0.9804]\n",
      "[0.004131467, 0.99987274]\n",
      "Epoca: 19 costo = 2.4474\n",
      "[0.14757785, 0.9808]\n",
      "[0.0034331405, 0.9998909]\n",
      "Epoca: 20 costo = 1.8907\n",
      "[0.1475261, 0.9812]\n",
      "[0.0025156979, 0.99994546]\n",
      "Epoca: 21 costo = 1.5135\n",
      "[0.14875497, 0.9806]\n",
      "[0.002345246, 0.99996364]\n",
      "Epoca: 22 costo = 1.4377\n",
      "[0.15185791, 0.9802]\n",
      "[0.0027526787, 0.9999091]\n",
      "Epoca: 23 costo = 1.3997\n",
      "[0.15081333, 0.9806]\n",
      "[0.0020006713, 0.99996364]\n",
      "Epoca: 24 costo = 1.0958\n",
      "[0.14819853, 0.981]\n",
      "[0.0017345127, 0.9999818]\n",
      "Epoca: 25 costo = 0.9998\n",
      "[0.15094084, 0.9812]\n",
      "[0.0016009293, 0.9999818]\n",
      "Epoca: 26 costo = 0.9383\n",
      "[0.15122367, 0.9814]\n",
      "[0.0014581747, 0.9999818]\n",
      "Epoca: 27 costo = 0.8509\n",
      "[0.15173171, 0.9814]\n",
      "[0.0013332969, 1.0]\n",
      "Epoca: 28 costo = 0.7853\n",
      "[0.15340912, 0.9814]\n",
      "[0.0012264457, 1.0]\n",
      "Epoca: 29 costo = 0.7153\n",
      "[0.1533118, 0.9816]\n",
      "[0.0011555145, 1.0]\n",
      "Epoca: 30 costo = 0.6782\n",
      "[0.15443756, 0.982]\n",
      "[0.0010957264, 1.0]\n",
      "\n",
      "Entrenamiento finalizado!\n",
      "[0.1539413, 0.9814]\n"
     ]
    }
   ],
   "source": [
    "# arrancar la sesión\n",
    "with tf.Session() as sess:\n",
    "    # inicializar las variables\n",
    "   \n",
    "    archivo=\"./summary_MNIST/ejecucion_\"+datetime.datetime.now().strftime(\"%Y-%m-%d--%H-%M\")\n",
    "    writer = tf.summary.FileWriter(archivo, sess.graph)\n",
    "    sess.run(inicializar)\n",
    "    total_lotes = int(len(mnist.train.labels) / tamaño_lote)\n",
    "    for epoca in range(epocas):\n",
    "        costos = []\n",
    "        costo_epoca = 0\n",
    "        for i in range(total_lotes):\n",
    "            merged = tf.summary.merge_all()\n",
    "            lote_x, lote_y = mnist.train.next_batch(batch_size=tamaño_lote)\n",
    "            summary, _, c = sess.run([merged, optimizador, costo], feed_dict={x: lote_x, y: lote_y})\n",
    "            costo_epoca += c\n",
    "            writer.add_summary(summary, epoca)\n",
    "        #costo_promedio /= total_lotes\n",
    "        costos.append(costo_epoca)\n",
    "        print(\"Epoca:\", (epoca + 1), \"costo =\", \"{:.4f}\".format(costo_epoca))\n",
    "        \n",
    "        print(sess.run([costo, exactitud], feed_dict={x: mnist.validation.images, y: mnist.validation.labels}))\n",
    "        print(sess.run([costo, exactitud], feed_dict={x: mnist.train.images, y: mnist.train.labels}))\n",
    "       \n",
    "\n",
    "    print(\"\\nEntrenamiento finalizado!\")\n",
    "    print(sess.run([costo, exactitud], feed_dict={x: mnist.test.images, y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizar Grafo Computacional de la Red Neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figuras/Grafo_RN_MNIST.png' width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizar Exactitud de Entrenamiento vs. Exactitud de Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "exactitud_entrenamiento = [0, 0.95503634, 0.97441816, 0.97996366, 0.9827818, 0.9876, 0.98752725, 0.9908182,\n",
    " 0.99203634, 0.9940364, 0.99527276, 0.9954, 0.9965636, 0.99645454, 0.99807274, 0.9984546, 0.99963635, \n",
    " 0.9996182, 0.99987274, 0.9998909, 0.99994546, 0.99996364, 0.9999091, 0.99996364, 0.9999818, 0.9999818, \n",
    " 0.9999818, 1.0, 1.0, 1.0, 1.0]\n",
    "\n",
    "exactitud_validacion = [0, 0.9548, 0.972, 0.973, 0.9774, 0.975, 0.9768, 0.9748,\n",
    " 0.9766, 0.9782, 0.9772, 0.9762, 0.9788, 0.9786, 0.979, 0.9794, 0.979, \n",
    " 0.979, 0.9804, 0.9808, 0.9812, 0.9806, 0.9802, 0.9806, 0.981, 0.9812, \n",
    " 0.9814, 0.9814, 0.9814, 0.9816, 0.982]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(epocas + 1), exactitud_entrenamiento)\n",
    "plt.plot(range(epocas + 1), exactitud_validacion)\n",
    "plt.title('Exactitud Entrenamiento vs. Validación')\n",
    "plt.ylabel('Exactitud')\n",
    "plt.xlabel('Epocas')\n",
    "plt.ylim([0.5, 1.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
